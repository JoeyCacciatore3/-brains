# LLM API Keys (Required)
# Get your API keys from:
# - Groq: https://console.groq.com/
# - Mistral: https://console.mistral.ai/
# - OpenRouter: https://openrouter.ai/

GROQ_API_KEY=your_groq_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter Fallback Models (Optional)
# Comma-separated list or JSON array of fallback models to try if primary model is unavailable
# Example: OPENROUTER_FALLBACK_MODELS=["openai/gpt-3.5-turbo","anthropic/claude-3-haiku"]
# Or: OPENROUTER_FALLBACK_MODELS=openai/gpt-3.5-turbo,anthropic/claude-3-haiku
# Default: ["openai/gpt-4o-mini","openai/gpt-3.5-turbo","anthropic/claude-3-haiku","google/gemini-flash-1.5","meta-llama/llama-3.2-3b-instruct:free"]
OPENROUTER_FALLBACK_MODELS=

# Application Settings
NEXT_PUBLIC_APP_URL=http://localhost:3000
APP_URL=http://localhost:3000
NODE_ENV=development

# Rate Limiting (Optional - defaults shown)
RATE_LIMIT_MAX_REQUESTS=10
RATE_LIMIT_WINDOW_MS=60000

# Conversation Limits (Optional - defaults shown)
# Maximum number of AI exchanges per conversation (each exchange = 2 messages, one from each AI)
# Default: 20 exchanges (40 messages total)
MAX_TURNS=20

# Discussion Token Limit (Optional - defaults shown)
# Token limit for discussions before summarization is triggered
# Default: 4000 tokens (50% of 8K context with safety buffer)
DISCUSSION_TOKEN_LIMIT=4000

# Optional: Monitoring (for production)
# Sentry: https://sentry.io/
SENTRY_DSN=

# Vercel Analytics (automatically enabled on Vercel)
VERCEL_ANALYTICS_ID=

# OAuth Authentication (Optional)
# Required if using Google or GitHub OAuth for user authentication
NEXTAUTH_SECRET=your_nextauth_secret_here
GOOGLE_CLIENT_ID=your_google_client_id_here
GOOGLE_CLIENT_SECRET=your_google_client_secret_here
GITHUB_CLIENT_ID=your_github_client_id_here
GITHUB_CLIENT_SECRET=your_github_client_secret_here

# Database Configuration (Optional - defaults shown)
# Path to SQLite database file
DATABASE_PATH=data/conversations.db

# Logging Configuration (Optional - defaults shown)
# Log level: debug, info, warn, error
LOG_LEVEL=info
NEXT_PUBLIC_LOG_LEVEL=info

# Server Configuration (Optional - defaults shown)
HOSTNAME=localhost
PORT=3000

# Socket.IO Configuration (Optional)
# Custom Socket.IO server URL (defaults to NEXT_PUBLIC_APP_URL)
NEXT_PUBLIC_SOCKET_URL=

# Redis Configuration (Optional - for distributed rate limiting)
# Use either REDIS_URL (connection string) or REDIS_HOST + REDIS_PORT
REDIS_URL=
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# File Storage Configuration (Optional - defaults shown)
# Directory for storing discussion files
DISCUSSIONS_DIR=data/discussions
